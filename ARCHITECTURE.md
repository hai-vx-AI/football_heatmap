# Football Video Analysis System - Architecture

This document provides a comprehensive overview of the four core modules that power the football video analysis system.

---

## Table of Contents

1. [Module 1: Player Detection (YOLO)](#module-1-player-detection-yolo)
2. [Module 2: Ball Detection & Prediction](#module-2-ball-detection--prediction)
3. [Module 3: Team Classification](#module-3-team-classification)
4. [Module 4: Real-Time Possession Analysis](#module-4-real-time-possession-analysis)

---

## Module 1: Player Detection (YOLO)

### Overview
The player detection module uses YOLO (You Only Look Once) deep learning models to identify and localize players, goalkeepers, referees, and balls in football video frames.

### How It Works

#### 1.1 Model Architecture
- **Model Type**: YOLO11/YOLOv8 based object detection
- **Input**: Video frames (RGB images)
- **Output**: Bounding boxes with class labels and confidence scores
- **Supported Classes**:
  - `player` (ID: 0)
  - `ball` (ID: 1)
  - `referee` (ID: 2)
  - `goalkeeper` (ID: 3)

#### 1.2 Detection Pipeline

```
Video Frame (BGR)
    â†“
Preprocessing (Letterbox resize to 1280x1280)
    â†“
YOLO Model Inference
    â†“
Non-Maximum Suppression (NMS)
    â†“
Per-Class Confidence Filtering
    â†“
Geometry Validation (Ball filters)
    â†“
Detections [bbox, confidence, class_id]
```

#### 1.3 Data Requirements

**Training Data Structure:**
```
input/SoccerNet/yolo_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ frame_001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ frame_001.txt  # YOLO format: class_id x_center y_center width height
â”‚       â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

**YOLO Label Format (normalized 0-1):**
```
0 0.512 0.345 0.089 0.156  # player at center (0.512, 0.345), size (0.089, 0.156)
1 0.678 0.234 0.012 0.015  # ball
2 0.123 0.456 0.067 0.134  # referee
```

#### 1.4 Model Training

**Quick Training:**
```bash
cd training
python train_yolo.py --data ../input/SoccerNet/yolo_dataset/dataset.yaml \
                     --model yolo11n.pt \
                     --epochs 100 \
                     --imgsz 1280
```

**Training Configuration (`training/training_config.yaml`):**
- **Epochs**: 100-300 (adjust based on dataset size)
- **Image Size**: 1280x1280 (balance between accuracy and speed)
- **Batch Size**: 16-32 (GPU dependent)
- **Augmentation**: Enabled (flip, rotation, mosaic, mixup)
- **Optimizer**: AdamW with cosine learning rate schedule

#### 1.5 Detection Parameters

| Parameter | Purpose | Default | Range |
|-----------|---------|---------|-------|
| `conf_global` | Global confidence threshold | 0.25 | 0.1-0.9 |
| `conf_player` | Player-specific threshold | 0.4 | 0.2-0.8 |
| `conf_ball` | Ball-specific threshold | 0.15 | 0.05-0.5 |
| `conf_referee` | Referee-specific threshold | 0.4 | 0.2-0.8 |
| `conf_goalkeeper` | Goalkeeper-specific threshold | 0.4 | 0.2-0.8 |
| `nms_iou` | NMS IoU threshold | 0.5 | 0.3-0.7 |
| `max_det` | Max detections per frame | 100 | 50-300 |

#### 1.6 Ball-Specific Filters

To reduce false positives, ball detections are filtered by:
- **Area**: `min_area_px=15`, `max_area_px=1500`
- **Aspect Ratio**: `min_aspect=0.6`, `max_aspect=1.8` (mostly circular)

#### 1.7 Model Files

- **Pretrained**: `yolo11n.pt`, `yolo11x.pt`, `yolov8x.pt`
- **Custom Trained**: `data/trained_models/yolo_football_best.pt`

**Implementation**: [`src/detector.py`](src/detector.py)

---

## Module 2: Ball Detection & Prediction

### Overview
The ball tracking module combines YOLO detections with Kalman Filter-based motion prediction to maintain stable ball trajectories even during occlusions or detection failures.

### What is Kalman Filter?

**Kalman Filter** is a mathematical algorithm that:
- **Estimates** the true state of a moving object from noisy measurements
- **Predicts** future positions based on motion models
- **Fuses** predictions with new observations optimally

**Why Kalman Filter for Ball Tracking?**

| Problem | Kalman Filter Solution |
|---------|----------------------|
| **Detection Failures** | Predict ball position when YOLO misses |
| **Noisy Detections** | Smooth out jittery/inaccurate detections |
| **Occlusions** | Continue tracking during temporary loss |
| **Velocity Estimation** | Estimate ball speed from position history |
| **Real-time Performance** | Extremely fast (no neural network needed) |

**How Kalman Filter Works:**

```
Step 1: PREDICT (Before seeing new detection)
â”œâ”€ Use motion model to predict where ball will be
â”œâ”€ Formula: x_predicted = F Ã— x_previous
â””â”€ Based on: last position + estimated velocity

Step 2: UPDATE (After getting new detection)
â”œâ”€ Compare prediction with actual detection
â”œâ”€ Compute Kalman Gain: How much to trust new measurement?
â”œâ”€ Formula: x_updated = x_predicted + K Ã— (measurement - prediction)
â””â”€ Result: Optimal fusion of prediction + observation

Step 3: REPEAT
â””â”€ Use updated state as input for next prediction
```

**Key Advantages over Pure YOLO:**
- âœ… **Handles missing detections** (predict during 10-15 frames gap)
- âœ… **Smoother trajectories** (removes detection jitter)
- âœ… **Velocity estimation** (YOLO only gives position)
- âœ… **Real-time speed** (runs at 1000+ FPS)
- âœ… **No training required** (mathematical model)

**Alternative: LSTM Ball Predictor**

The project also includes an optional **LSTM-based predictor** ([training/train_ball_predictor.py](training/train_ball_predictor.py)) for advanced trajectory prediction:

| Method | Speed | Accuracy | Training | Best For |
|--------|-------|----------|----------|----------|
| **Kalman Filter** | âš¡ Very Fast | âœ… Good | âŒ None | Real-time tracking, short gaps |
| **LSTM Predictor** | ðŸ¢ Slower | âœ¨ Better | âœ… Required | Long occlusions, complex patterns |

**Current Implementation:** Uses Kalman Filter for optimal real-time performance.

### How It Works

#### 2.1 Two-Phase Tracking System

**Phase 1: Detection-Based Tracking**
- When YOLO detects the ball â†’ use detection directly
- Status: `'detected'`

**Phase 2: Prediction-Based Tracking**
- When YOLO fails to detect â†’ predict ball position using Kalman Filter
- Status: `'predicted'`

**Phase 3: Lost Tracking**
- After 15 consecutive misses â†’ trigger reacquisition or mark as lost
- Status: `'lost'`

#### 2.2 Kalman Filter Motion Model

**State Vector (4D):**
```
x = [cx, cy, vx, vy]
    â†‘    â†‘   â†‘   â†‘
    |    |   |   â””â”€ velocity_y (pixels/frame)
    |    |   â””â”€â”€â”€â”€â”€ velocity_x (pixels/frame)
    |    â””â”€â”€â”€â”€â”€â”€â”€ center_y (pixel coordinate)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ center_x (pixel coordinate)
```

**Why track velocity?**
- Allows prediction when ball not detected
- Smoother trajectory estimation
- Can detect sudden changes (kicks, bounces)

**State Transition Matrix F (Constant Velocity Model):**

Assumes ball moves with constant velocity between frames (good approximation for short time intervals).

```
x(t+1) = F Ã— x(t)

         â”Œ                    â”
         â”‚ 1  0  dt  0       â”‚  â† cx_new = cx_old + vx Ã— dt
         â”‚ 0  1  0   dt      â”‚  â† cy_new = cy_old + vy Ã— dt
F =      â”‚ 0  0  1   0       â”‚  â† vx_new = vx_old (constant)
         â”‚ 0  0  0   1       â”‚  â† vy_new = vy_old (constant)
         â””                    â”˜

where dt = 1/fps (time step)
For 25 fps: dt = 0.04 seconds
```

**Example Prediction:**
```python
# Current state
cx = 500 px
cy = 300 px
vx = 20 px/frame  # moving right
vy = -10 px/frame # moving up

# Prediction for next frame (dt = 0.04s)
cx_next = 500 + 20 Ã— 1 = 520 px
cy_next = 300 + (-10) Ã— 1 = 290 px
vx_next = 20 px/frame (unchanged)
vy_next = -10 px/frame (unchanged)
```

**Measurement Matrix H:**

We only measure position (cx, cy) from YOLO, not velocity.

```
         â”Œ           â”
         â”‚ 1  0  0  0â”‚  â† Measure cx
H =      â”‚ 0  1  0  0â”‚  â† Measure cy
         â””           â”˜

z(t) = H Ã— x(t) = [cx, cy]
```

**Kalman Update Equation:**

When new YOLO detection arrives, combine prediction with measurement:

```
Innovation = z(t) - H Ã— x_predicted(t)  # Difference between detection and prediction
K = Kalman Gain  # How much to tr Effect |
|-----------|---------|---------|--------|
| `track_buffer` | Max frames to keep predicting | 15 | Higher = track longer during occlusion |
| `max_displacement_px_per_frame` | Motion gating radius | 80 px | Max ball speed (2000 px/sec at 25fps) |
| `gate_radius_scale` | Search radius multiplier | 1.5x | Tolerance for prediction error |
| `process_noise_pos` | Position uncertainty (Q) | 1.0 | Higher = trust measurements more |
| `process_noise_vel` | Velocity uncertainty (Q) | 0.1 | Higher = allow velocity changes |
| `measurement_noise` | Detection noise (R) | 10.0 | Higher = trust predictions more |

**Tuning Guidelines:**

**For slow-moving ball (passing, rolling):**
```yaml
process_noise_pos: 0.5    # Smooth motion
process_noise_vel: 0.05   # Steady velocity
measurement_noise: 5.0    # Trust YOLO
```

**For fast-moving ball (shots, long passes):**
```yaml
process_noise_pos: 2.0    # Allow quick position changes
process_noise_vel: 0.5    # Allow velocity changes
measurement_noise: 15.0   # YOLO may be inaccurate
max_displacement_px_per_frame: 120  # Higher speed limit
```

**For noisy detections:**
```yaml
measurement_noise: 20.0   # Don't trust YOLO too much
track_buffer: 20          # Predict longer during gaps
``` are YOLO detections?)

```
K â‰ˆ Prediction_Uncertainty / (Prediction_Uncertainty + Measurement_Noise)

If YOLO is accurate (low R):  K â†’ 1 (trust measurement more)
If YOLO is noisy (high R):    K â†’ 0 (trust prediction more)
```

**Noise Covariance Matrices:**

```python
# Process Noise Q (motion model uncertainty)
Q = diag([q_pos, q_pos, q_vel, q_vel])
q_pos = 1.0   # Position uncertainty (pixelsÂ²)
q_vel = 0.1   # Velocity uncertainty (pixelsÂ²/frameÂ²)

# Measurement Noise R (YOLO detection uncertainty)
R = diag([r, r])
r = 10.0  # Detection noise (pixelsÂ²)
```

**Physical Interpretation:**
- **Q large**: Ball motion is unpredictable (quick kicks, bounces)
- **Q small**: Ball follows smooth trajectory (rolling, passing)
- **R large**: YOLO detections are noisy (trust predictions more)
- **R small**: YOLO detections are accurate (trust measurements more)

#### 2.3 Tracking Pipeline

```
Frame N
    â†“
YOLO Detection â†’ Ball Detections (0-N bboxes)
    â†“
Motion Gating (filter by max displacement)
    â†“
Association (nearest to prediction)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MATCHED â”‚ NO MATCHâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â†“         â†“
  Update KF  Predict Only
  Status='detected'  Status='predicted'
     â†“         â†“
  Miss=0    Miss++
     â†“         â†“
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â†“
    miss_counter > 15?
          â†“
        YES â†’ Reacquisition
        NO  â†’ Continue
```

#### 2.4 Reacquisition Strategy

When the ball is lost for 5+ frames, the tracker attempts to reacquire it:

1. **Create Search ROI**: Expand 4x around last known position
2. **Run YOLO in ROI**: Focused detection in smaller region
3. **Validate Candidates**: Check geometry and confidence
4. **Reinitialize Tracker**: Reset Kalman filter with new detection

**Reacquisition Frequency**: Every 3 frames during loss

#### 2.5 Key Parameters

| Parameter | Purpose | Default |
|-----------|---------|---------|
| `track_buffer` | Max frames to keep predicting | 15 |
| `max_displacement_px_per_frame` | Motion gating radius | 80 px |
| `gate_radius_scale` | Search radius multiplier | 1.5x |
| `process_noise_pos` | Position uncertainty | 1.0 |
| `process_noise_vel` | Velocity uncertainty | 0.1 |
| `measurement_noise` | Detection noise | 5.0 |

#### 2.6 Output State

Each frame, the ball tracker returns:
```python
{
    'status': 'detected' | 'predicted' | 'lost',
    'bbox': [x1, y1, x2, y2],           # Current bounding box
    'center': (cx, cy),                  # Current center
    'velocity': (vx, vy),                # Estimated velocity (px/frame)
    'confidence': float,                 # Detection confidence (0 if predicted)
    'miss_counter': int,                 # Consecutive missed detections
    'trajectory': [(cx, cy), ...],       # Recent trajectory (last 30 frames)
}
```

**Implementation**: [`src/ball_tracker.py`](src/ball_tracker.py)

---

## Module 3: Team Classification

### Overview
The team classification module assigns each player to one of two teams based on jersey color analysis using clustering and temporal smoothing.

### How It Works

#### 3.1 Color-Based Classification Pipeline

```
Player Detection (bbox)
    â†“
1. Crop Jersey ROI
   (x: 20%-80%, y: 15%-55% of bbox)
    â†“
2. Preprocess
   - Convert BGR â†’ Lab color space
   - Apply grass mask (remove green pixels)
   - Filter dark pixels (shadow removal)
    â†“
3. Extract Dominant Color
   - Compute median/mean of remaining pixels
    â†“
4. Assign to Team
   - Distance to team centroids (Euclidean in Lab)
   - Assign to nearest cluster
    â†“
5. Temporal Smoothing
   - Per-track EMA (Exponential Moving Average)
   - Voting over last 30 frames
    â†“
Team ID (0 or 1)
```

#### 3.2 Jersey ROI Extraction

**Why only jersey region?**
- Avoids legs/shorts (often same color for both teams or grass)
- Focuses on most discriminative area
- Reduces noise from background

**Crop Parameters:**
```
ROI = bbox[
    x_start : x_end,  # 0.2 to 0.8 (central 60% horizontally)
    y_start : y_end   # 0.15 to 0.55 (chest area vertically)
]
```

#### 3.3 Color Space: Lab vs RGB

**Lab Color Space Advantages:**
- **L**: Lightness (0-100) - separates brightness
- **a**: Green-Red axis (-128 to 127)
- **b**: Blue-Yellow axis (-128 to 127)
- **Perceptually uniform**: Euclidean distance matches human perception
- **Illumination invariant**: Separates color from brightness

**Distance Metric:**
```
distance = âˆš[(L1-L2)Â² + (a1-a2)Â² + (b1-b2)Â²]
```

#### 3.4 Two-Phase Team Learning

**Phase 1: Warmup (First 200 frames)**
- Collect jersey color samples from all players
- Build global sample set (100+ samples minimum)
- Run K-Means clustering (K=2) to find team centroids

**Phase 2: Online Classification (After warmup)**
- Assign players by distance to centroids
- Update centroids incrementally (EMA with Î²=0.01)
- Apply per-track temporal smoothing

#### 3.5 Temporal Smoothing

**Per-Track EMA:**
```python
color_ema[track_id] = Î± Ã— color_new + (1 - Î±) Ã— color_ema[track_id]
```
- **Î± = 0.2**: Balance between stability and responsiveness

**Voting Window:**
- Keep last 30 team assignments per track
- Final team = majority vote (threshold 60%)
- Prevents flickering between teams

#### 3.6 Goalkeeper Handling

Goalkeepers often wear different colors than their team. Solution:

**Neighbor Voting Method:**
1. Find nearby players within 300px radius
2. Count team assignments of neighbors
3. Assign goalkeeper to majority team (threshold 50%)

**Alternative**: Manual assignment via config

#### 3.7 Grass Mask & Filters

**Grass Removal (HSV):**
- Hue: 35-85 (green range)
- Saturation: > 60
- Value: > 40
- Purpose: Remove grass pixels from jersey ROI

**Dark Pixel Filter:**
- L < 20 in Lab space
- Purpose: Remove shadows and very dark regions

#### 3.8 Key Parameters

| Parameter | Purpose | Default |
|-----------|---------|---------|
| `warmup_frames` | Frames to collect samples | 200 |
| `min_init_samples` | Min samples for clustering | 100 |
| `n_teams` | Number of teams | 2 |
| `ema_alpha` | Per-track color smoothing | 0.2 |
| `vote_window_frames` | Voting window size | 30 |
| `vote_threshold` | Majority vote threshold | 0.6 |
| `centroid_update_beta` | Centroid EMA weight | 0.01 |

#### 3.9 Output

Each player track is augmented with:
```python
{
    'team_id': 0 or 1,           # Assigned team
    'team_color_lab': [L, a, b], # Smoothed jersey color
    'team_confidence': float,    # Voting confidence (0-1)
}
```

**Special Cases:**
- Referees: `team_id = None` (not assigned)
- Goalkeepers: Assigned via neighbor voting or manual config

**Implementation**: [`src/team_assigner.py`](src/team_assigner.py)

---

## Module 4: Real-Time Possession Analysis

### Overview
The possession analysis module determines which player/team controls the ball and tracks possession statistics in real-time.

### How It Works

#### 4.1 Possession Detection Logic

**Basic Rule:**
```
Player has possession IF:
    distance(player_center, ball_center) â‰¤ possession_radius
```

**Default Radius**: 150 pixels (adjustable based on video resolution)

#### 4.2 Possession Pipeline

```
Frame N
    â†“
Ball State (detected/predicted/lost)
    â†“
Ball Lost? â†’ No Possession
    â†“ NO
Find Nearest Player to Ball
    â†“
Distance â‰¤ 150px?
    â†“ YES
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POSSESSION FOUND â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Same Player as Last Frame?
         â†“
    YES â†’ Continue Possession
    NO  â†’ Check Pass Criteria
         â†“
    New Possession Event
         â†“
    Update Statistics
```

#### 4.3 Possession Smoothing

To avoid flickering:

**Minimum Possession Duration:**
- Player must be nearest for 5+ consecutive frames to count as possessor
- Prevents random noise from triggering possession changes

**Smoothing Window:**
- Keep possession history for last 15 frames
- Smooth possession team using majority vote

#### 4.4 Pass Detection

**Pass Criteria:**
```
Pass detected IF:
    1. Possession changed from Player A to Player B
    2. Player A and B are on different teams (optional)
    3. Distance between A and B > min_pass_distance (200px)
    4. Time between possessions < max_pass_duration (50 frames / 2 seconds)
```

**Pass Event Structure:**
```python
{
    'frame_idx': int,
    'from_player_id': int,
    'to_player_id': int,
    'from_team': 0 or 1,
    'to_team': 0 or 1,
    'distance': float,           # Distance between players (px)
    'duration_frames': int,      # Frames between possessions
    'successful': bool,          # True if same team
}
```

#### 4.5 Real-Time Statistics

**Per Frame Output:**
```python
{
    'possessor_id': int or None,         # Current player with ball
    'possessor_team': 0 or 1 or None,    # Current possessing team
    'possession_duration_sec': float,     # How long current player has ball
    'team_possession_pct': {              # Overall possession percentages
        'team_0': 45.2,
        'team_1': 54.8
    },
    'recent_pass': {...} or None,        # Pass info if just detected
}
```

#### 4.6 Statistics Tracking

**Team-Level:**
- Total possession frames per team
- Possession percentage (frames with ball / total frames)
- Possession time in seconds
- Number of passes (successful + unsuccessful)

**Player-Level:**
- Individual possession frames per player
- Individual possession time
- Passes made by each player

#### 4.7 Computation Flow

```python
# Pseudo-code
for each frame:
    if ball_lost:
        possessor = None
    else:
        # Find nearest player
        nearest = min(players, key=lambda p: distance(p, ball))
        
        if distance(nearest, ball) <= radius:
            if nearest == current_possessor:
                # Continue possession
                possession_duration += 1
            else:
                # Check for pass
                if meets_pass_criteria(current, nearest):
                    record_pass(current, nearest)
                
                # New possession
                current_possessor = nearest
                possession_duration = 0
        else:
            possessor = None
    
    # Update statistics
    if possessor:
        team_frames[possessor.team] += 1
        player_frames[possessor.id] += 1
    
    # Compute percentages
    total_frames = sum(team_frames.values())
    for team in teams:
        team_pct[team] = 100 * team_frames[team] / total_frames
```

#### 4.8 Key Parameters

| Parameter | Purpose | Default |
|-----------|---------|---------|
| `possession_radius_px` | Max distance for possession | 150 px |
| `min_frames_for_possession` | Min frames to count | 5 |
| `smoothing_window_frames` | Possession smoothing window | 15 |
| `min_pass_distance_px` | Min distance to count as pass | 200 px |
| `max_pass_duration_frames` | Max time between passes | 50 |

#### 4.9 Rendering

**Visual Indicators:**
- **Possession Highlight**: Circle around player with ball (team color)
- **Possession Bar**: Top overlay showing team percentages
- **Pass Arrow**: Animated arrow showing recent pass direction

**Text Overlays:**
- Current possessor name/ID
- Possession duration
- Team possession percentages

**Implementation**: [`src/possession_analyzer.py`](src/possession_analyzer.py)

---

## Integration Flow

### Complete Pipeline

```
Video Frame
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 1: PLAYER DETECTION (YOLO)  â”‚
â”‚ Input:  Frame (BGR image)           â”‚
â”‚ Output: Detections [bbox, class]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚   Split     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¤
    â†“      â†“      â†“
 Players Ball  Refs
    â”‚      â”‚      â”‚
    â†“      â†“      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ People Tracker (ByteTrack)        â”‚ 
â”‚ Output: Tracks [id, bbox, class]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 2: BALL DETECTION/PREDICT   â”‚
â”‚ Input:  Ball detections + history  â”‚
â”‚ Output: Ball state [center, vel]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 3: TEAM CLASSIFICATION      â”‚
â”‚ Input:  Player tracks + frame      â”‚
â”‚ Output: Tracks with team_id        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MODULE 4: POSSESSION ANALYSIS      â”‚
â”‚ Input:  Tracks + ball state        â”‚
â”‚ Output: Possession stats           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
        Renderer
           â†“
     Output Video
```

---

## Configuration

All modules are configurable via `config.yaml`:

```yaml
# Module 1: Detection
detector:
  model_path: 'data/trained_models/yolo_football_best.pt'
  conf_player: 0.4
  conf_ball: 0.15
  # ...

# Module 2: Ball Tracking
ball_tracker:
  track_buffer: 15
  max_displacement_px_per_frame: 80
  reacquire:
    enabled: true
    roi_scale: 4.0
  # ...

# Module 3: Team Classification
team_color:
  enabled: true
  warmup_frames: 200
  ema_alpha: 0.2
  # ...

# Module 4: Possession
possession:
  enabled: true
  possession_radius_px: 150
  pass_detection_enabled: true
  # ...
```

---

## Performance Optimization

### Speed vs Accuracy Trade-offs

| Component | Fast | Balanced | Accurate |
|-----------|------|----------|----------|
| YOLO Model | yolo11n | yolo11m | yolo11x |
| Input Size | 640 | 1280 | 1280 |
| Conf Threshold | 0.5 | 0.4 | 0.3 |
| Track Buffer | 10 | 15 | 20 |
| Warmup Frames | 100 | 200 | 300 |

### Hardware Requirements

**Minimum (CPU):**
- 4-core CPU
- 8GB RAM
- ~0.5-1 FPS processing speed

**Recommended (GPU):**
- NVIDIA GPU with 6GB+ VRAM
- 16GB RAM
- ~25-30 FPS processing speed (real-time)

---

## Troubleshooting

### Common Issues

**1. Ball Detection Failures:**
- Lower `conf_ball` threshold (0.15 â†’ 0.10)
- Increase `track_buffer` (15 â†’ 25)
- Enable reacquisition

**2. Team Misclassification:**
- Increase `warmup_frames` (200 â†’ 500)
- Adjust grass mask HSV ranges for different field colors
- Check if jersey colors are too similar

**3. Possession Flickering:**
- Increase `possession_radius_px` (150 â†’ 200)
- Increase `smoothing_window_frames` (15 â†’ 30)
- Increase `min_frames_for_possession` (5 â†’ 10)

---

## References

- **YOLO**: [Ultralytics YOLOv8/YOLO11](https://github.com/ultralytics/ultralytics)
- **Kalman Filter**: [FilterPy Library](https://github.com/rlabbe/filterpy)
- **ByteTrack**: [Multi-Object Tracking](https://github.com/ifzhang/ByteTrack)
- **Color Spaces**: [OpenCV Color Conversions](https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html)

---

**Last Updated**: December 30, 2025
